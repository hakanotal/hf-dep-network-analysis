{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "edges = pd.read_csv('network_data/edges.csv')\n",
    "nodes = pd.read_csv('network_data/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>herisan/llama-3-8b_mental_health_counseling_co...</td>\n",
       "      <td>Cas-Warehouse/Llama-3-Mopeyfied-Psychology-v2</td>\n",
       "      <td>merged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart-the-bag/MysticFusion-13B</td>\n",
       "      <td>TheBloke/MysticFusion-13B-GGUF</td>\n",
       "      <td>quantized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walmart-the-bag/MysticFusion-13B</td>\n",
       "      <td>TheBloke/MysticFusion-13B-GPTQ</td>\n",
       "      <td>quantized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walmart-the-bag/MysticFusion-13B</td>\n",
       "      <td>TheBloke/MysticFusion-13B-AWQ</td>\n",
       "      <td>quantized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genaforvena/the_soft_delerizome_machine_a_thou...</td>\n",
       "      <td>genaforvena/the_soft_scum_delerizome_machine_a...</td>\n",
       "      <td>finetuned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  herisan/llama-3-8b_mental_health_counseling_co...   \n",
       "1                   Walmart-the-bag/MysticFusion-13B   \n",
       "2                   Walmart-the-bag/MysticFusion-13B   \n",
       "3                   Walmart-the-bag/MysticFusion-13B   \n",
       "4  genaforvena/the_soft_delerizome_machine_a_thou...   \n",
       "\n",
       "                                              target       edge  \n",
       "0      Cas-Warehouse/Llama-3-Mopeyfied-Psychology-v2     merged  \n",
       "1                     TheBloke/MysticFusion-13B-GGUF  quantized  \n",
       "2                     TheBloke/MysticFusion-13B-GPTQ  quantized  \n",
       "3                      TheBloke/MysticFusion-13B-AWQ  quantized  \n",
       "4  genaforvena/the_soft_scum_delerizome_machine_a...  finetuned  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>time</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>private</th>\n",
       "      <th>gated</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_arch</th>\n",
       "      <th>base_models</th>\n",
       "      <th>base_models_count</th>\n",
       "      <th>type_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lxyyxl/DeepSeek-R1-Distill-Qwen-1.5B</td>\n",
       "      <td>lxyyxl</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-26 06:32:45+00:00</td>\n",
       "      <td>2025-02-26 06:33:57+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>finetuned</td>\n",
       "      <td>qwen2</td>\n",
       "      <td>['unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unslot...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'finetune_source': 'unsloth/DeepSeek-R1-Disti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>herisan/llama-3-8b_mental_health_counseling_co...</td>\n",
       "      <td>herisan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>base</td>\n",
       "      <td>llama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walmart-the-bag/MysticFusion-13B</td>\n",
       "      <td>Walmart-the-bag</td>\n",
       "      <td>297</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-18 02:53:37+00:00</td>\n",
       "      <td>2024-03-12 17:12:20+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>base</td>\n",
       "      <td>llama</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jamesdborin/llama2-7b-base-4bit-AWQ</td>\n",
       "      <td>jamesdborin</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-11 09:26:17+00:00</td>\n",
       "      <td>2023-12-11 09:26:17+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>quantized</td>\n",
       "      <td>llama</td>\n",
       "      <td>['meta-llama/Llama-2-7b-hf']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'quantization_source': 'meta-llama/Llama-2-7b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genaforvena/the_soft_delerizome_machine_a_thou...</td>\n",
       "      <td>genaforvena</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-31 17:56:47+00:00</td>\n",
       "      <td>2025-01-06 03:41:41+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>finetuned</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>['openai-community/gpt2', 'openai-community/gp...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'finetune_source': 'openai-community/gpt2', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id           author  \\\n",
       "0               lxyyxl/DeepSeek-R1-Distill-Qwen-1.5B           lxyyxl   \n",
       "1  herisan/llama-3-8b_mental_health_counseling_co...          herisan   \n",
       "2                   Walmart-the-bag/MysticFusion-13B  Walmart-the-bag   \n",
       "3                jamesdborin/llama2-7b-base-4bit-AWQ      jamesdborin   \n",
       "4  genaforvena/the_soft_delerizome_machine_a_thou...      genaforvena   \n",
       "\n",
       "   downloads  likes                       time              last_modified  \\\n",
       "0         11      0  2025-02-26 06:32:45+00:00  2025-02-26 06:33:57+00:00   \n",
       "1          0      0                        NaN                        NaN   \n",
       "2        297      3  2023-11-18 02:53:37+00:00  2024-03-12 17:12:20+00:00   \n",
       "3         17      0  2023-12-11 09:26:17+00:00  2023-12-11 09:26:17+00:00   \n",
       "4         20      0  2024-12-31 17:56:47+00:00  2025-01-06 03:41:41+00:00   \n",
       "\n",
       "  private  gated model_type model_arch  \\\n",
       "0   False  False  finetuned      qwen2   \n",
       "1   False  False       base      llama   \n",
       "2   False  False       base      llama   \n",
       "3   False  False  quantized      llama   \n",
       "4   False  False  finetuned       gpt2   \n",
       "\n",
       "                                         base_models  base_models_count  \\\n",
       "0  ['unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unslot...                2.0   \n",
       "1                                                NaN                NaN   \n",
       "2                                                 []                0.0   \n",
       "3                       ['meta-llama/Llama-2-7b-hf']                1.0   \n",
       "4  ['openai-community/gpt2', 'openai-community/gp...                2.0   \n",
       "\n",
       "                                        type_details  \n",
       "0  {'finetune_source': 'unsloth/DeepSeek-R1-Disti...  \n",
       "1                                                NaN  \n",
       "2                                                 {}  \n",
       "3  {'quantization_source': 'meta-llama/Llama-2-7b...  \n",
       "4  {'finetune_source': 'openai-community/gpt2', '...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 nodes for degree centrality: [('unsloth/llama-3-8b-bnb-4bit', 0.02465634592286134), ('unsloth/Meta-Llama-3.1-8B-Instruct', 0.017716535433070866), ('unsloth/Phi-3-mini-4k-instruct-bnb-4bit', 0.01628186307220072), ('meta-llama/Llama-3.1-8B', 0.012111303883624717), ('meta-llama/Llama-3.1-8B-Instruct', 0.011377285466435341), ('unsloth/Phi-3.5-mini-instruct', 0.010976911784332044), ('unsloth/llama-3-8b-Instruct-bnb-4bit', 0.010176164420125451), ('mistralai/Mistral-7B-v0.1', 0.009975977579073803), ('unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit', 0.008808221006272522), ('unsloth/Meta-Llama-3.1-8B-bnb-4bit', 0.00800747364206593)]\n",
      "Top 10 nodes for betweenness centrality: [('meta-llama/Meta-Llama-3-8B-Instruct', 0.022632992833051303), ('mistralai/Mistral-7B-Instruct-v0.3', 0.02071510138237894), ('Chan-Y/MistraLlama', 0.019537203058913176), ('meta-llama/Llama-3.1-8B-Instruct', 0.01859640045642727), ('mistralai/Mistral-7B-v0.1', 0.016938381984946644), ('nitky/Oumuamua-7b-instruct', 0.0160074959409197), ('meta-llama/Meta-Llama-3-8B', 0.01158439260855793), ('unsloth/llama-3-8b-bnb-4bit', 0.010626787674975144), ('meta-llama/Llama-3.1-8B', 0.010010511732277481), ('arcee-ai/Llama-3.1-SuperNova-Lite', 0.009496808365268696)]\n",
      "Top 10 nodes for closeness centrality: [('meta-llama/Meta-Llama-3-8B-Instruct', 0.04384567755447149), ('DavidAU/Llama-3.1-Dark-Planet-8B-SuperNova', 0.0435658686147498), ('meta-llama/Llama-3.1-8B-Instruct', 0.04291064875440914), ('meta-llama/Meta-Llama-3-8B', 0.042311935055537694), ('arcee-ai/Llama-3.1-SuperNova-Lite', 0.042026477574980854), ('DavidAU/L3-Dark-Planet-8B', 0.041583453766093764), ('Sao10K/L3-8B-Stheno-v3.2', 0.04127235847096867), ('NeverSleep/Llama-3-Lumimaid-8B-v0.1-OAS', 0.04078706624614293), ('MathGenie/MathCoder2-Llama-3-8B', 0.04072928632828531), ('mergekit-community/L3.1-Athena-l-8B', 0.04066060848139381)]\n",
      "Top 10 nodes for clustering coefficient: [('altomek/Phil-18B-il1', 1.0), ('bamec66557/MISCHIEVOUS-12B-Mix_0.6v', 1.0), ('ValiantLabs/Qwen3-14B-Cobalt2', 1.0), ('allura-org/MS-Meadowlark-22B', 1.0), ('3rd-Degree-Burn/L-3.1-Science-Writer-8B-v0', 1.0), ('mpasila/Viking-Magnum-v0.1-7B', 1.0), ('pipihand01/QwQ-32B-Preview-abliterated-linear25', 1.0), ('pipihand01/QwQ-32B-Preview-abliterated-linear50', 1.0), ('pipihand01/QwQ-32B-Preview-abliterated-linear75', 1.0), ('DavidAU/MN-DARKEST-UNIVERSE-29B-GGUF', 1.0)]\n",
      "Top 10 nodes for PageRank: [('unsloth/llama-3-8b-bnb-4bit', 0.011508043783753903), ('unsloth/Meta-Llama-3.1-8B-Instruct', 0.00835847903821884), ('unsloth/Phi-3-mini-4k-instruct-bnb-4bit', 0.007717754032637022), ('meta-llama/Llama-3.1-8B', 0.005346165747775416), ('unsloth/Phi-3.5-mini-instruct', 0.005186188813494676), ('meta-llama/Llama-3.1-8B-Instruct', 0.004901351878055536), ('unsloth/llama-3-8b-Instruct-bnb-4bit', 0.004783000961006833), ('unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit', 0.004125475195235092), ('mistralai/Mistral-7B-v0.1', 0.0038868052787519184), ('unsloth/Meta-Llama-3.1-8B-bnb-4bit', 0.0037901742282985033)]\n"
     ]
    }
   ],
   "source": [
    "G = nx.from_pandas_edgelist(edges, source='source', target='target')\n",
    "\n",
    "# Calculate centrality metrics\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# Calculate clustering coefficients\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "\n",
    "# Calculate PageRank\n",
    "page_rank = nx.pagerank(G)\n",
    "\n",
    "\n",
    "# print the top 10 nodes for each centrality metric\n",
    "print(f\"Top 10 nodes for degree centrality: {sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
    "print(f\"Top 10 nodes for betweenness centrality: {sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
    "print(f\"Top 10 nodes for closeness centrality: {sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
    "print(f\"Top 10 nodes for clustering coefficient: {sorted(clustering_coefficient.items(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
    "print(f\"Top 10 nodes for PageRank: {sorted(page_rank.items(), key=lambda x: x[1], reverse=True)[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
